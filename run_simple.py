"""
å°çº¢ä¹¦è‡ªåŠ¨åŒ–ç³»ç»Ÿ - ç®€åŒ–ç‰ˆå¯åŠ¨è„šæœ¬

ç»•è¿‡å¤æ‚ä¾èµ–ï¼Œç›´æ¥è¿è¡Œæ ¸å¿ƒåŠŸèƒ½
"""

import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent))

print("=" * 60)
print("ğŸš€ å°çº¢ä¹¦è‡ªåŠ¨åŒ–ç³»ç»Ÿ - å¯åŠ¨ä¸­...")
print("=" * 60)
print()

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
try:
    from app.xiaohongshu.hot_topics import HotTopicsCollector
    from app.xiaohongshu.demand_analyzer import DemandAnalyzer
    from app.xiaohongshu.content_generator import ContentGenerator
    from app.xiaohongshu.safety_controller import SafetyController
    from app.xiaohongshu.config import get_config
    from app.llm import LLM
    print("âœ… æ ¸å¿ƒæ¨¡å—åŠ è½½æˆåŠŸ")
except Exception as e:
    print(f"âŒ æ¨¡å—åŠ è½½å¤±è´¥: {e}")
    print()
    print("è¯·æ£€æŸ¥ä¾èµ–æ˜¯å¦å®‰è£…å®Œæ•´")
    input("æŒ‰å›è½¦é”®é€€å‡º...")
    sys.exit(1)

print()
print("ğŸ“‹ å¯ç”¨åŠŸèƒ½:")
print("1. æµ‹è¯• DeepSeek API")
print("2. åˆ†æçƒ­ç‚¹å†…å®¹ï¼ˆæ‰‹åŠ¨è¾“å…¥ï¼‰")
print("3. ç”Ÿæˆå›å¤å†…å®¹")
print()

choice = input("è¯·é€‰æ‹©åŠŸèƒ½ (1/2/3): ").strip()

if choice == "1":
    print()
    print("=" * 60)
    print("ğŸ§ª æµ‹è¯• DeepSeek API")
    print("=" * 60)
    print()

    from openai import OpenAI
    client = OpenAI(
        api_key="sk-b07c9af227fa49b68ff1f6e4ae36465f",
        base_url="https://api.deepseek.com"
    )

    prompt = input("è¯·è¾“å…¥æµ‹è¯•æ¶ˆæ¯: ").strip()
    if not prompt:
        prompt = "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"

    print(f"\nğŸ“¨ å‘é€: {prompt}")
    print()

    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=500
    )

    result = response.choices[0].message.content
    print(f"ğŸ¤– DeepSeek å›å¤:")
    print("-" * 60)
    print(result)
    print("-" * 60)

elif choice == "2":
    print()
    print("=" * 60)
    print("ğŸ“Š åˆ†æçƒ­ç‚¹å†…å®¹")
    print("=" * 60)
    print()

    title = input("è¯·è¾“å…¥çƒ­ç‚¹æ ‡é¢˜: ").strip()
    content = input("è¯·è¾“å…¥çƒ­ç‚¹å†…å®¹: ").strip()

    if not title or not content:
        print("âŒ æ ‡é¢˜å’Œå†…å®¹ä¸èƒ½ä¸ºç©º")
    else:
        print()
        print("ğŸ” æ­£åœ¨åˆ†æ...")

        from app.xiaohongshu.prompts import get_prompt

        llm = LLM()
        prompt = get_prompt(
            'hot_topic_analysis',
            title=title,
            content=content,
            likes=100,
            comments=50,
            collects=80,
            top_comments="ç”¨æˆ·A: å¤ªå®ç”¨äº†\nç”¨æˆ·B: æ±‚æ¨è"
        )

        response = llm.generate(
            prompt=prompt,
            system_prompt=get_prompt('system')
        )

        print()
        print("ğŸ“ åˆ†æç»“æœ:")
        print("-" * 60)
        print(response)
        print("-" * 60)

elif choice == "3":
    print()
    print("=" * 60)
    print("ğŸ’¬ ç”Ÿæˆå›å¤å†…å®¹")
    print("=" * 60)
    print()

    title = input("è¯·è¾“å…¥å¸–å­æ ‡é¢˜: ").strip()
    pain_point = input("è¯·è¾“å…¥ç”¨æˆ·ç—›ç‚¹: ").strip()
    demand = input("è¯·è¾“å…¥æ ¸å¿ƒéœ€æ±‚: ").strip()

    if not title:
        print("âŒ æ ‡é¢˜ä¸èƒ½ä¸ºç©º")
        pain_point = "éœ€è¦è§£å†³è¿™ä¸ªé—®é¢˜"
        demand = "ç”¨æˆ·å¸Œæœ›è·å¾—å¸®åŠ©"

    print()
    print("âœï¸ æ­£åœ¨ç”Ÿæˆå›å¤...")

    from app.xiaohongshu.prompts import get_prompt

    llm = LLM()
    prompt = get_prompt(
        'content_generation',
        title=title,
        pain_point=pain_point or "éœ€è¦è§£å†³å…·ä½“é—®é¢˜",
        demand=demand or "ç”¨æˆ·éœ€è¦è·å¾—å¸®åŠ©",
        angle="ç»éªŒåˆ†äº«"
    )

    response = llm.generate(
        prompt=prompt,
        system_prompt=get_prompt('system')
    )

    print()
    print("ğŸ“ ç”Ÿæˆçš„å›å¤:")
    print("-" * 60)
    print(response)
    print("-" * 60)

else:
    print("âŒ æ— æ•ˆé€‰æ‹©")

print()
print("=" * 60)
print("âœ… è¿è¡Œå®Œæˆï¼")
print("=" * 60)
print()
input("æŒ‰å›è½¦é”®é€€å‡º...")

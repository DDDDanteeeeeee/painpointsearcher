"""
å°çº¢ä¹¦ä¸» Agent

æ•´åˆæ‰€æœ‰æ¨¡å—ï¼Œå®ç°å®Œæ•´çš„å·¥ä½œæµç¨‹
"""

import asyncio
from datetime import datetime
from pathlib import Path
from typing import List, Optional
from pydantic import BaseModel, Field

from app.llm import LLM
from app.logger import logger
from app.xiaohongshu.config import get_config
from app.xiaohongshu.hot_topics import HotTopicsCollector, HotTopic
from app.xiaohongshu.demand_analyzer import DemandAnalyzer, TopicAnalysis
from app.xiaohongshu.content_generator import ContentGenerator, ReplySet
from app.xiaohongshu.auto_replier import AutoReplier
from app.xiaohongshu.safety_controller import SafetyController
from app.xiaohongshu.prompts import get_prompt


class WorkflowResult(BaseModel):
    """å·¥ä½œæµç»“æœ"""
    success: bool = Field(description="æ˜¯å¦æˆåŠŸ")
    topics_collected: int = Field(default=0, description="æ”¶é›†çš„çƒ­ç‚¹æ•°")
    topics_analyzed: int = Field(default=0, description="åˆ†æçš„è¯é¢˜æ•°")
    replies_generated: int = Field(default=0, description="ç”Ÿæˆçš„å›å¤æ•°")
    replies_sent: int = Field(default=0, description="å‘é€çš„å›å¤æ•°")
    duration_seconds: float = Field(default=0, description="è€—æ—¶ï¼ˆç§’ï¼‰")
    errors: List[str] = Field(default_factory=list, description="é”™è¯¯åˆ—è¡¨")


class XiaohongshuAgent:
    """å°çº¢ä¹¦ Agent"""

    def __init__(self):
        self.config = get_config().get()
        self.llm = LLM()

        # åˆå§‹åŒ–å„æ¨¡å—
        self.collector = HotTopicsCollector()
        self.analyzer = DemandAnalyzer()
        self.generator = ContentGenerator()
        self.replier = AutoReplier()
        self.safety = SafetyController()

        self._initialized = False

    async def initialize(self):
        """åˆå§‹åŒ– Agent"""
        if self._initialized:
            return

        logger.info("åˆå§‹åŒ–å°çº¢ä¹¦ Agent...")

        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        self.config.workspace_root.mkdir(parents=True, exist_ok=True)
        self.config.hot_topics_dir.mkdir(parents=True, exist_ok=True)
        self.config.analysis_dir.mkdir(parents=True, exist_ok=True)
        self.config.content_dir.mkdir(parents=True, exist_ok=True)
        self.config.logs_dir.mkdir(parents=True, exist_ok=True)

        self._initialized = True
        logger.info("âœ… Agent åˆå§‹åŒ–å®Œæˆ")

    async def run_full_workflow(self, max_topics: int = 20, max_replies: int = 5) -> WorkflowResult:
        """
        è¿è¡Œå®Œæ•´å·¥ä½œæµ

        Args:
            max_topics: æœ€å¤§æ”¶é›†çƒ­ç‚¹æ•°
            max_replies: æœ€å¤§å›å¤æ•°

        Returns:
            å·¥ä½œæµç»“æœ
        """
        await self.initialize()

        start_time = datetime.now()
        result = WorkflowResult(success=True)

        logger.info("=" * 60)
        logger.info("ğŸš€ å¼€å§‹å°çº¢ä¹¦è‡ªåŠ¨åŒ–å·¥ä½œæµ")
        logger.info("=" * 60)

        try:
            # Phase 1: æ”¶é›†çƒ­ç‚¹
            logger.info("\nğŸ“ Phase 1: æ”¶é›†çƒ­ç‚¹")
            topics = await self.safety.execute_with_safety(
                self.collector.collect_from_explore_page,
                "collect_hot_topics",
                max_topics
            )

            if not topics:
                logger.warning("æœªæ”¶é›†åˆ°çƒ­ç‚¹ï¼Œå·¥ä½œæµç»ˆæ­¢")
                result.success = False
                return result

            result.topics_collected = len(topics)
            logger.info(f"âœ… æ”¶é›†åˆ° {len(topics)} ä¸ªçƒ­ç‚¹")

            # Phase 2: åˆ†æéœ€æ±‚
            logger.info("\nğŸ“ Phase 2: åˆ†æéœ€æ±‚")
            analyses = await self.safety.execute_with_safety(
                self.analyzer.analyze_batch,
                "analyze_topics",
                topics
            )

            result.topics_analyzed = len(analyses)
            logger.info(f"âœ… åˆ†æäº† {len(analyses)} ä¸ªè¯é¢˜")

            # è·å– TOP è¯é¢˜
            top_topics = self.analyzer.get_top_topics(analyses, top_n=max_replies)
            logger.info(f"\nğŸ† TOP {len(top_topics)} é«˜ä»·å€¼è¯é¢˜ï¼š")
            for i, analysis in enumerate(top_topics, 1):
                logger.info(f"  {i}. {analysis.topic.title} (ä¼˜å…ˆçº§: {analysis.priority:.2f})")

            # Phase 3: ç”Ÿæˆå›å¤
            logger.info("\nğŸ“ Phase 3: ç”Ÿæˆå›å¤å†…å®¹")
            reply_sets = []

            for i, analysis in enumerate(top_topics, 1):
                logger.info(f"\n[{i}/{len(top_topics)}] ä¸º '{analysis.topic.title}' ç”Ÿæˆå›å¤...")

                # æ£€æŸ¥æ˜¯å¦å¯ä»¥å›å¤
                can_reply, reason = self.replier.can_reply_now()
                if not can_reply:
                    logger.warning(f"è·³è¿‡: {reason}")
                    continue

                # ç”Ÿæˆå›å¤
                reply_set = await self.safety.execute_with_safety(
                    self.generator.generate_replies,
                    "generate_replies",
                    analysis,
                    num_versions=5
                )

                if reply_set and reply_set.best_reply:
                    reply_sets.append(reply_set)
                    result.replies_generated += 1

                    # Phase 4: å‘é€å›å¤ï¼ˆåŠè‡ªåŠ¨ï¼‰
                    if self.config.require_human_review:
                        logger.info("\nğŸ“ Phase 4: å‡†å¤‡å‘é€ï¼ˆéœ€äººå·¥ç¡®è®¤ï¼‰")
                        success = await self.safety.execute_with_safety(
                            self.replier.send_reply,
                            "send_reply",
                            reply_set.best_reply,
                            analysis.topic.url,
                            analysis.topic.title,
                            auto_send=False
                        )

                        if success:
                            result.replies_sent += 1
                            logger.info("âœ… å›å¤å‘é€æˆåŠŸ")
                        else:
                            logger.warning("âŒ å›å¤å‘é€å¤±è´¥æˆ–è¢«å–æ¶ˆ")

                    # é¢‘ç‡æ§åˆ¶
                    if i < len(top_topics):
                        await self.safety.apply_random_delay("between_replies")

            # ç”Ÿæˆæ—¥æŠ¥
            if self.config.save_analysis_report:
                await self._generate_daily_report(topics, analyses, reply_sets)

        except Exception as e:
            logger.error(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            result.success = False
            result.errors.append(str(e))

        # ç»Ÿè®¡è€—æ—¶
        result.duration_seconds = (datetime.now() - start_time).total_seconds()

        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“Š å·¥ä½œæµæ‰§è¡Œç»“æœ:")
        logger.info(f"  - æ”¶é›†çƒ­ç‚¹: {result.topics_collected} ä¸ª")
        logger.info(f"  - åˆ†æè¯é¢˜: {result.topics_analyzed} ä¸ª")
        logger.info(f"  - ç”Ÿæˆå›å¤: {result.replies_generated} ä¸ª")
        logger.info(f"  - å‘é€å›å¤: {result.replies_sent} ä¸ª")
        logger.info(f"  - æ€»è€—æ—¶: {result.duration_seconds:.1f} ç§’")
        logger.info("=" * 60)

        return result

    async def collect_only(self, max_topics: int = 20) -> List[HotTopic]:
        """ä»…æ”¶é›†çƒ­ç‚¹"""
        await self.initialize()

        logger.info("ğŸ“ æ”¶é›†çƒ­ç‚¹...")

        topics = await self.safety.execute_with_safety(
            self.collector.collect_from_explore_page,
            "collect_hot_topics",
            max_topics
        )

        logger.info(f"âœ… æ”¶é›†åˆ° {len(topics)} ä¸ªçƒ­ç‚¹")
        return topics

    async def analyze_only(self, topics: List[HotTopic]) -> List[TopicAnalysis]:
        """ä»…åˆ†æçƒ­ç‚¹"""
        await self.initialize()

        logger.info(f"ğŸ“ åˆ†æ {len(topics)} ä¸ªçƒ­ç‚¹...")

        analyses = await self.safety.execute_with_safety(
            self.analyzer.analyze_batch,
            "analyze_topics",
            topics
        )

        logger.info(f"âœ… åˆ†æå®Œæˆ")
        return analyses

    async def generate_only(self, analyses: List[TopicAnalysis], max_replies: int = 5) -> List[ReplySet]:
        """ä»…ç”Ÿæˆå›å¤"""
        await self.initialize()

        logger.info(f"ğŸ“ ä¸º TOP {max_replies} è¯é¢˜ç”Ÿæˆå›å¤...")

        top_topics = self.analyzer.get_top_topics(analyses, top_n=max_replies)
        reply_sets = []

        for i, analysis in enumerate(top_topics, 1):
            logger.info(f"[{i}/{len(top_topics)}] {analysis.topic.title}")

            reply_set = await self.safety.execute_with_safety(
                self.generator.generate_replies,
                "generate_replies",
                analysis
            )

            if reply_set:
                reply_sets.append(reply_set)

        logger.info(f"âœ… ç”Ÿæˆ {len(reply_sets)} ç»„å›å¤")
        return reply_sets

    async def reply_one(self, url: str, auto_send: bool = False) -> bool:
        """
        ä¸ºå•ä¸ªå¸–å­ç”Ÿæˆå¹¶å‘é€å›å¤

        Args:
            url: å¸–å­é“¾æ¥
            auto_send: æ˜¯å¦è‡ªåŠ¨å‘é€

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        await self.initialize()

        logger.info(f"ğŸ“ å¤„ç†å•ä¸ªå¸–å­: {url}")

        try:
            # æ”¶é›†
            topic = await self.collector.collect_from_specific_url(url)
            if not topic:
                logger.error("æ— æ³•æ”¶é›†å¸–å­ä¿¡æ¯")
                return False

            # åˆ†æ
            analysis = await self.analyzer.analyze_topic(topic)

            # ç”Ÿæˆ
            reply_set = await self.generator.generate_replies(analysis)
            if not reply_set or not reply_set.best_reply:
                logger.error("æ— æ³•ç”Ÿæˆå›å¤")
                return False

            # å‘é€
            success = await self.replier.send_reply(
                reply_set.best_reply,
                url,
                topic.title,
                auto_send=auto_send
            )

            return success

        except Exception as e:
            logger.error(f"å¤„ç†å¤±è´¥: {e}")
            return False

    async def _generate_daily_report(
        self,
        topics: List[HotTopic],
        analyses: List[TopicAnalysis],
        reply_sets: List[ReplySet]
    ):
        """ç”Ÿæˆæ—¥æŠ¥"""
        logger.info("ç”Ÿæˆæ—¥æŠ¥...")

        # å‡†å¤‡æ•°æ®
        daily_data = {
            "date": datetime.now().strftime("%Y-%m-%d"),
            "topics_count": len(topics),
            "top_topics": [
                {
                    "title": t.topic.title,
                    "url": t.topic.url,
                    "priority": t.priority,
                    "commercial_value": t.commercial_value
                }
                for t in analyses[:5]
            ],
            "replies_generated": len(reply_sets),
            "replies": [
                {
                    "topic": rs.topic_title,
                    "best_content": rs.best_reply.content if rs.best_reply else "",
                    "score": rs.best_reply.overall_score if rs.best_reply else 0
                }
                for rs in reply_sets
            ]
        }

        # ä½¿ç”¨ LLM ç”ŸæˆæŠ¥å‘Š
        try:
            prompt = get_prompt('daily_report', daily_data=str(daily_data))
            report = self.llm.generate(
                prompt=prompt,
                system_prompt=get_prompt('system')
            )

            # ä¿å­˜æŠ¥å‘Š
            report_path = self.config.logs_dir / f"daily_report_{datetime.now().strftime('%Y%m%d')}.md"
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(report)

            logger.info(f"âœ… æ—¥æŠ¥å·²ä¿å­˜: {report_path}")

        except Exception as e:
            logger.warning(f"ç”Ÿæˆæ—¥æŠ¥å¤±è´¥: {e}")

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        logger.info("æ¸…ç†èµ„æº...")
        # æ¸…ç†æµè§ˆå™¨ç­‰èµ„æº
        self._initialized = False
